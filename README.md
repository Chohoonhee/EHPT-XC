# EHPT-XC
Official project page for "A Benchmark Dataset for Event-Guided Human Pose Estimation and Tracking in Extreme Conditions" (NeurIPS2024)


## Abstract
Multi-person pose estimation and tracking have been actively researched by the computer vision community due to their practical applicability. However, existing human pose estimation and tracking datasets have only been successful in typical scenarios, such as those without motion blur or with well-lit conditions. These RGB-based datasets are limited to learning under extreme motion blur situations or poor lighting conditions, making them inherently vulnerable to such scenarios.
As a promising solution, bio-inspired event cameras exhibit robustness in extreme scenarios due to their high dynamic range and micro-second level temporal resolution. Therefore, in this paper, we introduce a new hybrid dataset encompassing both RGB and event data for human pose estimation and tracking in two extreme scenarios: low-light and motion blur environments. The proposed Event-guided Human Pose Estimation and Tracking in eXtreme Conditions (EHPT-XC) dataset covers cases of motion blur caused by dynamic objects and low-light conditions individually as well as both simultaneously. With EHPT-XC, we aim to inspire researchers to tackle pose estimation and tracking in extreme conditions by leveraging the advantageous of the event camera.


## How to get the dataset?
In order to obtain the EHPT-XC dataset, please fill out [this document](https://github.com/Chohoonhee/EHPT-XC/blob/main/usage_agreement.pdf) and send it to **gnsgnsgml[at]kaist[dot]ac[dot]kr** or **jeongyh98[at]kaist[dot]ac[dot]kr**. Please note that we require a (digitally) handwritten signature.

**NOTE**: Please don't request write access to the template of the agreement sheet. Download the agreement sheet and fill it locally on your computer and send it to us.

